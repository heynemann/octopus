{"name":"Octopus","tagline":"octopus is a library to use threads to concurrently retrieve and report on the completion of http requests","body":"octopus\r\n=======\r\n\r\n[![Build Status](https://travis-ci.org/heynemann/octopus.png?branch=master)](https://travis-ci.org/heynemann/octopus)\r\n[![PyPi version](https://pypip.in/v/octopus-http/badge.png)](https://crate.io/packages/octopus-http/)\r\n[![PyPi downloads](https://pypip.in/d/octopus-http/badge.png)](https://crate.io/packages/octopus-http/)\r\n[![Coverage Status](https://coveralls.io/repos/heynemann/octopus/badge.png?branch=master)](https://coveralls.io/r/heynemann/octopus?branch=master)\r\n\r\n`octopus` is a library to concurrently retrieve and report on the completion of http requests.\r\n\r\nYou can either use threads or the tornado IOLoop to asynchronously get them.\r\n\r\nInstalling\r\n==========\r\n\r\nInstalling `octopus` is really easy:\r\n\r\n    $ pip install octopus-http\r\n\r\nThe reason for the name of the package is that a package called `octopus` was already registered at the Python Package Index.\r\n\r\nUsing\r\n=====\r\n\r\nUsing `octopus` with threads:\r\n\r\n    from octopus import Octopus\r\n\r\n    # this Octopus instance we'll run 4 threads,\r\n    # automatically start listening to the queue and\r\n    # we'll in-memory cache responses for 10 seconds.\r\n    otto = Octopus(\r\n        concurrency=4, auto_start=True, cache=True,\r\n        expiration_in_seconds=10\r\n    )\r\n\r\n    def handle_url_response(url, response):\r\n        # do something with response\r\n\r\n    otto.enqueue('http://www.google.com', handle_url_response)\r\n    otto.enqueue('http://www.facebook.com', handle_url_response)\r\n    otto.enqueue('http://www.yahoo.com', handle_url_response)\r\n\r\n    # this request will come from the cache\r\n    otto.enqueue('http://www.google.com', handle_url_response)  \r\n\r\n    otto.wait()  # waits until queue is empty or timeout is ellapsed\r\n\r\nThe analogous version with Tornado's IOLoop:\r\n\r\n    from octopus import TornadoOctopus\r\n\r\n    # this Octopus instance we'll run 4 concurrent requests max,\r\n    # automatically start listening to the queue and\r\n    # we'll in-memory cache responses for 10 seconds.\r\n    otto = TornadoOctopus(\r\n        concurrency=4, auto_start=True, cache=True,\r\n        expiration_in_seconds=10\r\n    )\r\n\r\n    def handle_url_response(url, response):\r\n        # do something with response\r\n\r\n    otto.enqueue('http://www.google.com', handle_url_response)\r\n    otto.enqueue('http://www.facebook.com', handle_url_response)\r\n    otto.enqueue('http://www.yahoo.com', handle_url_response)\r\n\r\n    # this request will come from the cache\r\n    otto.enqueue('http://www.google.com', handle_url_response)  \r\n\r\n    otto.wait()  # waits until queue is empty or timeout is ellapsed\r\n\r\nAPI Reference\r\n=============\r\n\r\nResponse Class\r\n--------------\r\n\r\nThe `Response` class is the result of all requests made with `Octopus` or `TornadoOctopus`.\r\n\r\nIt has the following information:\r\n\r\n* `url` - the url that started the request;\r\n* `status_code` - the status code for the request;\r\n* `cookies` - dictionary with request cookie values;\r\n* `headers` - dictionary with response headers;\r\n* `text` - the body of the response;\r\n* `effective_url` - in the case of redirects, this url might be different than url;\r\n* `error` - if an error has occurred this is where the error message will be;\r\n* `request_time` - the time ellapsed between the start and the end of the request in seconds.\r\n\r\nOctopus Class\r\n-------------\r\n\r\nThis is the main unit of work in `octopus` if you want to use threads. To enqueue new urls you need to have an `Octopus` instance:\r\n\r\n    from octopus import Octopus\r\n\r\n    otto = Octopus()\r\n\r\nThe constructor for `Octopus` takes several configuration options:\r\n\r\n* `concurrency`: number of threads to use to retrieve URLs (defaults to 10 threads);\r\n* `auto_start`: Indicates whether threads should be started automatically (defaults to False);\r\n* `cache`: If set to `True`, responses will be cached for the number of seconds specified in `expiration_in_seconds` (defaults to False);\r\n* `expiration_in_seconds`: The number of seconds to keep url responses in the local cache (defaults to 30 seconds);\r\n* `request_timeout_in_seconds`: The number of seconds that each request can take (defaults to 5 seconds).\r\n* `limiter`: The instance of a limiter class to use to acquire limits (more on limits below).\r\n\r\nOctopus.start()\r\n---------------\r\n\r\nIf `auto_start` is set to `False`, this method must be called to start retrieving URLs. This is a **non-blocking** method.\r\n\r\nOctopus.enqueue\r\n---------------\r\n\r\nTakes as arguments (url, handler, method=\"GET\", **kwargs).\r\n\r\nThis is the main method in the `Octopus` class. This method is used to enqueue new URLs. The handler argument specifies the method to be called when the response is available.\r\n\r\nThe handler takes the form `handler(url, response)`. The response argument is a Octopus.Response instance.\r\n\r\nYou can specify a different method using the `method` argument (`POST`, `HEAD`, etc) and you can pass extra keyword arguments to the `requests.request` method using the keyword arguments for this method.\r\n\r\nThis is a **non-blocking** method.\r\n\r\nOctopus.queue_size\r\n------------------\r\n\r\nThis property returns the approximate number of URLs still in the queue (not retrieved yet).\r\n\r\nOctopus.is_empty\r\n----------------\r\n\r\nThis property returns if the URL queue is empty.\r\n\r\nOctopus.wait(timeout=10)\r\n------------------------\r\n\r\nIf you want to wait for all the URLs in the queue to finish loading, just call this method.\r\n\r\nIf you specify a `timeout` of `0`, `octopus` will wait until the queue is empty, no matter how long it takes.\r\n\r\nThis is a **blocking** method.\r\n\r\nTornadoOctopus Class\r\n--------------------\r\n\r\nThis is the main unit of work in `octopus` if you want to use Tornado's IOLoop. To enqueue new urls you need to have an `TornadoOctopus` instance:\r\n\r\n    from octopus import TornadoOctopus\r\n\r\n    otto = TornadoOctopus()\r\n\r\nA **very important** thing that differs from the threaded version of Octopus is that you **MUST** call wait to get the responses, since Tornado IOLoop needs to be run in order to get the requests.\r\n\r\nThe constructor for `TornadoOctopus` takes several configuration options:\r\n\r\n* `concurrency`: number of maximum async http requests to use to retrieve URLs (defaults to 10 requests);\r\n* `auto_start`: Indicates whether the ioloop should be created automatically (defaults to False);\r\n* `cache`: If set to `True`, responses will be cached for the number of seconds specified in `expiration_in_seconds` (defaults to False);\r\n* `expiration_in_seconds`: The number of seconds to keep url responses in the local cache (defaults to 30 seconds);\r\n* `request_timeout_in_seconds`: The number of seconds that each request can take (defaults to 10 seconds).\r\n* `connect_timeout_in_seconds`: The number of seconds that each connection can take (defaults to 5 seconds).\r\n* `limiter`: The instance of a limiter class to use to acquire limits (more on limits below).\r\n\r\nTornadoOctopus.start()\r\n---------------\r\n\r\nIf `auto_start` is set to `False`, this method must be called to create the IOLoop instance. This is a **non-blocking** method.\r\n\r\nTornadoOctopus.enqueue\r\n----------------------\r\n\r\nTakes as arguments (url, handler, method=\"GET\", **kwargs).\r\n\r\nThis is the main method in the `TornadoOctopus` class. This method is used to enqueue new URLs. The handler argument specifies the method to be called when the response is available.\r\n\r\nThe handler takes the form `handler(url, response)`. The response argument is a Octopus.Response instance.\r\n\r\nYou can specify a different method using the `method` argument (`POST`, `HEAD`, etc) and you can pass extra keyword arguments to the `AsyncHTTPClient.fetch` method using the keyword arguments for this method.\r\n\r\nThis is a **non-blocking** method.\r\n\r\nTornadoOctopus.queue_size\r\n-------------------------\r\n\r\nThis property returns the number of URLs still in the queue (not retrieved yet).\r\n\r\nTornadoOctopus.is_empty\r\n-----------------------\r\n\r\nThis property returns if the URL queue is empty.\r\n\r\nTornadoOctopus.wait(timeout=10)\r\n-------------------------------\r\n\r\nIn order for the IOLoop to handle callbacks, you **MUST** call wait. This is the method that gets the IOLoop to run.\r\n\r\nIf you specify a `timeout` of `0`, `octopus` will wait until the queue is empty, no matter how long it takes.\r\n\r\nThis is a **blocking** method.\r\n\r\nLimiting Simultaneous Connections\r\n=================================\r\n\r\nA very common problem that can happen when using octopus is overwhelming the server you are going to. In order to make sure this\r\ndoes not happen, Octopus allows users to specify a limiter class.\r\n\r\nEach limiter class has to provide two methods `acquire` and `release`, both taking an URL as argument.\r\n\r\nOctopus comes bundled with an in-memory limiter and a redis limiter (courtesy of the [retools project](https://github.com/bbangert/retools)). Using limiters is as simple as passing it to octopus constructor:\r\n\r\n    from octopus import TornadoOctopus\r\n    from octopus.limiter.in_memory.per_domain import Limiter\r\n\r\n    # using in-memory limiter. Domains not specified here have no limit.\r\n    limiter = Limiter(\r\n        {'http://globo.com': 10},  # only 10 concurrent requests to this domain\r\n        {'http://g1.globo.com': 20},  # only 20 concurrent requests to this domain\r\n    )\r\n\r\n    otto = TornadoOctopus(\r\n        concurrency=4, auto_start=True, cache=True,\r\n        expiration_in_seconds=10,\r\n        limiter=limiter\r\n    )\r\n\r\nThe available built-in limiters are:\r\n\r\n* `octopus.limiter.in_memory.per_domain.Limiter`\r\n* `octopus.limiter.redis.per_domain.Limiter`\r\n\r\nBoth take a list of dictionaries with the key being the beginning of the URL and value being the allowed concurrent connections.\r\n\r\nThe reason this is a list is that urls defined first take precedence. This allows users to single out a path in a domain that needs less connections than the rest of the domain, like this:\r\n\r\n    # using in-memory limiter. Domains not specified here have no limit.\r\n    limiter = Limiter(\r\n        {'http://g1.globo.com/economia': 5},  # only 5 concurrent requests to urls that begin with this key\r\n        {'http://g1.globo.com': 20},  # only 20 concurrent requests to the rest of the domain\r\n    )\r\n\r\nThe redis limiter takes two additional keyword arguments:\r\n `redis` (a [redis.py](https://github.com/andymccurdy/redis-py) connection to redis)\r\n and `expiration_in_seconds` (the expiration for locks in the limiter).\r\n\r\n**WARNING**: The in-memory limiter **IS NOT** thread-safe, so if you are using Threaded Octopus, do not use this limiter.\r\n\r\nBenchmark\r\n=========\r\n\r\nIn order to decide whether `octopus` really was worth using, it features a benchmark test in it's codebase.\r\n\r\nIf you want to run it yourself (which is highly encouraged), just clone `octopus` repository and run this command:\r\n\r\n    $ python benchmark/test_octopus.py 200 100\r\n\r\nThe first argument is the number of URLs to retrieve. The seconds argument means how many threads will be used by `octopus` to get the urls.\r\n\r\nThe test is pretty simple. Time how long it takes for requests to get the URLs sequentially and for `octopus` to get them concurrently.\r\n\r\nThe results for retrieving `2000` urls with `200` threads is as follows:\r\n\r\n    =======\r\n    RESULTS\r\n    =======\r\n\r\n    [requests] Retrieving 2000 urls took 2692.66 seconds meaning 0.74 urls/second.\r\n\r\n    [octopus] Retrieving 2000 urls took 31.14 seconds meaning 64.22 urls/second.\r\n\r\n    [octopus] Retrieving 2000 urls with local in-memory caching took 6.61 seconds\r\n    meaning 302.50 urls/second.\r\n\r\n    [octopus-tornado] Retrieving 2000 urls took 167.99 seconds\r\n    meaning 11.91 urls/second.\r\n\r\n    [octopus-tornado-pycurl] Retrieving 2000 urls took 171.40 seconds\r\n    meaning 11.67 urls/second.\r\n\r\n    Overall, threaded octopus was more than 86 times faster than sequential requests\r\n    and tornado octopus was more than 15 times faster than sequential requests.\r\n","google":"UA-45782943-1","note":"Don't delete this file! It's used internally to help with page regeneration."}